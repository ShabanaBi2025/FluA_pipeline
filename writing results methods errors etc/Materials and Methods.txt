Materials and Methods
Data Acquisition and Reference Genomes
Raw sequencing data for influenza A virus subtypes H1N1 and H3N2 were obtained from the NCBI Sequence Read Archive (SRA). The dataset comprised both paired-end Illumina short-read data and Oxford Nanopore Technologies (ONT) long-read data.

Reference genomes for Influenza A/H1N1(pdm09) and A/H3N2 were acquired from the NCBI Nucleotide database. A custom script (main_clean_refs.nf) was utilized to prepare these references for analysis. This preparation involved simplifying FASTA headers to retain only the accession number and generating the necessary index files for alignment using BWA (version X.X) and samtools (version X.X).

Bioinformatics Workflow Management
All data processing and analysis were orchestrated using a series of modular pipelines developed with the Nextflow workflow management system (version 25.04.6). This approach ensures the reproducibility, scalability, and portability of the analysis. All software dependencies were managed through distinct Conda environments for each stage of the analysis, guaranteeing version consistency and isolating toolsets.

Read Quality Control and Pre-processing
Initial quality assessment of the raw FASTQ files was performed using FastQC (version X.X). For Illumina data, adapter sequences and low-quality bases were removed using Trimmomatic (version X.X). For ONT data, reads were filtered based on quality scores using NanoFilt (version X.X).

Sequence Alignment
Following pre-processing, reads were aligned to the appropriate strain-specific reference genome. Illumina paired-end reads were aligned using the BWA-MEM algorithm. ONT long reads were aligned using Minimap2 (version X.X) with the map-ont preset, which is optimized for long, noisy reads. The resulting alignments were then sorted and converted to the binary BAM format using samtools.

Variant Calling and Consensus Sequence Generation
Single Nucleotide Polymorphisms (SNPs) and insertions/deletions (Indels) were identified from the alignment files. The bcftools mpileup command was used to summarize the base calls at each position of the reference genome, and bcftools call with the -mv flag was used to call variants. A haploid ploidy (--ploidy 1) was assumed for the viral genomes.

A consensus genome sequence for each sample was generated using bcftools consensus. This command substitutes the variant bases from the VCF file into the reference sequence. For samples where no variants were detected, the original reference genome was used as the consensus sequence.

Phylogenetic and Clade Analysis with Nextclade
To determine the genetic clade and identify key mutations, the consensus sequences were analyzed with Nextclade (version X.X). As the available Nextclade influenza datasets are specific to the hemagglutinin (HA) gene, a pre-processing step was implemented. The HA segment was first extracted from each multi-segment consensus FASTA file using samtools faidx. Any IUPAC ambiguity codes within the extracted HA sequence were replaced with 'N' to ensure compatibility with the Nextclade alignment algorithm.

The prepared HA sequences were then analyzed using the appropriate strain-specific Nextclade dataset (flu_h1n1pdm_ha or flu_h3n2_ha). The analysis produced a comprehensive report for each sample, including clade assignment, a list of nucleotide and amino acid substitutions relative to the Nextclade reference, and quality control metrics.

Materials and Methods
Data Acquisition and Reference Genomes
Raw sequencing data for influenza A virus subtypes H1N1 and H3N2 were obtained from the NCBI Sequence Read Archive (SRA). The dataset comprised both paired-end Illumina short-read data and Oxford Nanopore Technologies (ONT) long-read data.

Reference genomes for Influenza A/H1N1(pdm09) and A/H3N2 were acquired from the NCBI Nucleotide database. A custom script (main_clean_refs.nf) was utilized to prepare these references for analysis. This preparation involved simplifying FASTA headers to retain only the accession number and generating the necessary index files for alignment using BWA (version X.X) and samtools (version X.X).

Bioinformatics Workflow Management
All data processing and analysis were orchestrated using a series of modular pipelines developed with the Nextflow workflow management system (version 25.04.6). This approach ensures the reproducibility, scalability, and portability of the analysis. All software dependencies were managed through distinct Conda environments for each stage of the analysis, guaranteeing version consistency and isolating toolsets.

Read Quality Control and Pre-processing
Initial quality assessment of the raw FASTQ files was performed using FastQC (version X.X). For Illumina data, adapter sequences and low-quality bases were removed using Trimmomatic (version X.X). For ONT data, reads were filtered based on quality scores using NanoFilt (version X.X).

Sequence Alignment
Following pre-processing, reads were aligned to the appropriate strain-specific reference genome. Illumina paired-end reads were aligned using the BWA-MEM algorithm. ONT long reads were aligned using Minimap2 (version X.X) with the map-ont preset, which is optimized for long, noisy reads. The resulting alignments were then sorted and converted to the binary BAM format using samtools.

Variant Calling and Consensus Sequence Generation
Single Nucleotide Polymorphisms (SNPs) and insertions/deletions (Indels) were identified from the alignment files. The bcftools mpileup command was used to summarize the base calls at each position of the reference genome, and bcftools call with the -mv flag was used to call variants. A haploid ploidy (--ploidy 1) was assumed for the viral genomes.

A consensus genome sequence for each sample was generated using bcftools consensus. This command substitutes the variant bases from the VCF file into the reference sequence. For samples where no variants were detected, the original reference genome was used as the consensus sequence.

Phylogenetic and Clade Analysis with Nextclade
To determine the genetic clade and identify key mutations, the consensus sequences were analyzed with Nextclade (version X.X). As the available Nextclade influenza datasets are specific to the hemagglutinin (HA) gene, a pre-processing step was implemented. The HA segment was first extracted from each multi-segment consensus FASTA file using samtools faidx. Any IUPAC ambiguity codes within the extracted HA sequence were replaced with 'N' to ensure compatibility with the Nextclade alignment algorithm.

The prepared HA sequences were then analyzed using the appropriate strain-specific Nextclade dataset (flu_h1n1pdm_ha or flu_h3n2_ha). The analysis produced a comprehensive report for each sample, including clade assignment, a list of nucleotide and amino acid substitutions relative to the Nextclade reference, and quality control metrics.







You ran a Nextflow pipeline that:

Aligned flu virus sequencing data (Illumina/ONT BAM files).

Called variants using bcftools against reference genomes.

Generated consensus sequences per sample.

Extracted HA segment from each consensus genome.

Analyzed those HA segments with Nextclade:

It aligned them to a reference.

Detected clades and mutations.

Produced phylogenetic and quality data.

üìÅ WHAT THESE FILES ARE
Each sample folder (e.g. nextclade/h1n1/SRR32055877/) contains outputs like:

File	Description
nextclade.aligned.fasta	Aligned HA sequence (against reference). Useful for tree building.
nextclade.csv	All results per sequence (clade, QC, mutations). Great for summary in Excel or R.
nextclade.json, .ndjson, .auspice.json	JSON formats for visualization in tools like Auspice (used by Nextstrain).
nextclade.tsv	Tab-delimited summary (easier for R, pandas, Excel).
nextclade.nwk	Newick tree format (for phylogenetic trees).
nextclade.cds_translation.HA1.fasta	Translated amino acid sequences (HA1 domain).
nextclade.gff	Genome feature annotations.
*.fasta	Consensus or aligned sequences for downstream use.


-------------------------
nput:

Sequencing reads (FASTQ files).

Reference genome (FASTA file).

Indexing:

The aligner first creates an index of the reference. This speeds up searching.

Different aligners use different algorithms (e.g., BWA uses Burrows-Wheeler Transform).

Mapping Reads:

The aligner scans each read and tries to find the best matching location(s) on the reference.

It accounts for mismatches, insertions, deletions (gaps) within a certain tolerance.

It scores these alignments and picks the best match(es).

Output:

A file in BAM or SAM format listing each read, its mapped position(s), alignment quality, and more.
